{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean version available at:  \n",
    "- https://github.com/Personalization-Technologies-Lab/RecSys-Course-HSE-Fall23/tree/main/Seminar3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing packages:\n",
    "```\n",
    "# polara\n",
    "pip install --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns # for better visual aesthetics\n",
    "sns.set_theme(style='white', context='paper')\n",
    "%config InlineBackend.figure_format = \"svg\"\n",
    "\n",
    "from polara import get_movielens_data\n",
    "\n",
    "from dataprep import leave_last_out, transform_indices, verify_time_split, reindex_data\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items, calculate_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this excercise, we will again work with the Movielens-1M data.  \n",
    "We will also follow the same \"most-recent-item in holdout\" strategy for simplicity.  \n",
    "So the preparation code is the same is in the previous lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_movielens_data(include_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_, holdout_ = leave_last_out(data, 'userid', 'timestamp')\n",
    "verify_time_split(training_, holdout_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, data_index = transform_indices(training_, 'userid', 'movieid')\n",
    "holdout = reindex_data(holdout_, data_index, filter_invalid=True)\n",
    "holdout = holdout.sort_values('userid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'rating',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    "    test_users = holdout[data_index['users'].name].values\n",
    ")\n",
    "data_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also explicitly store our testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid = data_description['users']\n",
    "seen_idx_mask = training[userid].isin(data_description['test_users'])\n",
    "testset = training[seen_idx_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on item-based KNN.  We define a few convenience functions first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interactions_matrix(data, data_description, rebase_users=False):\n",
    "    '''\n",
    "    Convert pandas dataframe with interactions into a sparse matrix.\n",
    "    Allows reindexing user ids, which help ensure data consistency\n",
    "    at the scoring stage (assumes user ids are sorted in scoring array).\n",
    "    '''\n",
    "    n_users = data_description['n_users']\n",
    "    n_items = data_description['n_items']\n",
    "    # get indices of observed data\n",
    "    user_idx = ... # type your code here\n",
    "    if rebase_users:\n",
    "        user_idx, user_index = pd.factorize(user_idx, sort=True)\n",
    "        n_users = len(user_index)\n",
    "    item_idx = ... # type your code here\n",
    "    feedback = ... # type your code here\n",
    "    # construct rating matrix\n",
    "    return csr_matrix((feedback, (user_idx, item_idx)), shape=(n_users, n_items))\n",
    "\n",
    "def cosine_similarity_zd(matrix):\n",
    "    '''Build cosine similarity matrix with zero diagonal.'''\n",
    "    similarity = ... # type your code here\n",
    "    return similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the main implementation starts here.  \n",
    "If $A$ is a matrix of ratings and  $S$ is an item-similarity matrix ($s_{ij}\\in[0, 1]$), then KNN-scores matrix $R$ is computed as:  \n",
    "\n",
    "- for elementwise weighting:\n",
    "$$\n",
    "R=A S^{\\top} \\oslash\\left(B S^{\\top}\\right),\\quad\n",
    "b_{u i}=\\left\\{\\begin{array}{lr}\n",
    "1, & \\text { if } a_{u i} \\text { is known } \\\\\n",
    "0 & \\text { otherwise }\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "- for row-wise weighting:\n",
    "$$\n",
    "R=AS^\\top D_S^{-1},\\quad\n",
    "D_S=\\operatorname{diag}(S\\mathbf{e})\n",
    "$$\n",
    "\n",
    "- for unweighted case:\n",
    "$$\n",
    "R=AS^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_iknn_model(config, data, data_description):\n",
    "    # compute similarity matrix\n",
    "    user_item_mtx = ... # type your code here\n",
    "    item_similarity = ... # type your code here\n",
    "    return ... # complete your code with necessary output\n",
    "\n",
    "\n",
    "def iknn_model_scoring(params, testset, testset_description):\n",
    "    ...\n",
    "    user_item_mtx = ... # your code to generate n_test_users x n_items matrix\n",
    "    return ... # complete your code with necessary output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iknn_params = ... # your code to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iknn_scores = ... # your code to gerenerate scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rating prediction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rmse(iknn_scores, holdout, data_description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top-n recommendations quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # your code to generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluate(iknn_recs, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to print metrics of all KNN models with different weightings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>\n",
    "\n",
    "- In your opinion, how the evaluation scores will change if we sample holdout items randomly?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyse aggregated statistics for movie ratings.  It may give us hints on performance of KNN  models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'unweighted' # name the weighting mode\n",
    "recommended_items = pd.Series(iknn_recs.ravel()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ratings = (\n",
    "    training\n",
    "    .groupby(data_description['items'])\n",
    "    [data_description['feedback']]\n",
    "    .agg(['size', 'mean', 'std'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ratings.loc[recommended_items.head(5).index] # top-5 most frequent recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = item_ratings.plot.scatter(\n",
    "    'size', 'mean', logx=True, alpha=0.3, figsize=(8, 6),\n",
    "    title=f'Rating distribution of recommended items, {mode=}'\n",
    ")\n",
    "item_ratings.loc[recommended_items.index].plot.scatter(\n",
    "    'size', 'mean', ax=ax, s=recommended_items*0.05, c='red'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = item_ratings.plot.scatter(\n",
    "    'mean', 'std', s=0.05*item_ratings['size'],\n",
    "    title=f'Rating deviation of recommended items, {mode=}'\n",
    ");\n",
    "item_ratings.loc[recommended_items.index].plot.scatter(\n",
    "    'mean', 'std', ax=ax, c='red', s=recommended_items*0.05\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_similarity(similarity, k):\n",
    "    '''\n",
    "    For every row in similarity matrix, pick at most k entities\n",
    "    with the highest similarity scores. Disregard everything else.\n",
    "    '''\n",
    "    similarity = similarity.tocsr()\n",
    "    inds = similarity.indices\n",
    "    ptrs = similarity.indptr\n",
    "    data = similarity.data\n",
    "    new_ptrs = [0]\n",
    "    new_inds = []\n",
    "    new_data = []\n",
    "    for i in range(len(ptrs)-1):\n",
    "        start, stop = ptrs[i], ptrs[i+1]\n",
    "        if start < stop:\n",
    "            data_ = data[start:stop]\n",
    "            topk = min(len(data_), k)\n",
    "            idx = np.argpartition(data_, -topk)[-topk:]\n",
    "            new_data.append(data_[idx])\n",
    "            new_inds.append(inds[idx+start])\n",
    "            new_ptrs.append(new_ptrs[-1]+len(idx))\n",
    "        else:\n",
    "            new_ptrs.append(new_ptrs[-1])\n",
    "    new_data = np.concatenate(new_data)\n",
    "    new_inds = np.concatenate(new_inds)\n",
    "    truncated = csr_matrix(\n",
    "        (new_data, new_inds, new_ptrs),\n",
    "        shape=similarity.shape\n",
    "    )\n",
    "    return truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iKNN with neighborhood sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sampled_iknn_model(config, data, data_description):\n",
    "    # compute similarity matrix\n",
    "    user_item_mtx = generate_interactions_matrix(data, data_description)\n",
    "    item_similarity = truncate_similarity(\n",
    "        cosine_similarity_zd(user_item_mtx.T),\n",
    "        config['n_neighbors']\n",
    "    )\n",
    "    return item_similarity, config['weighting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 100\n",
    "\n",
    "iknn_params_uw = build_sampled_iknn_model(\n",
    "    {'weighting': None, 'n_neighbors': n_neighbors}, training, data_description\n",
    ")\n",
    "iknn_params_ew = build_sampled_iknn_model(\n",
    "    {'weighting': 'elementwise', 'n_neighbors': n_neighbors}, training, data_description\n",
    ")\n",
    "iknn_params_rw = build_sampled_iknn_model(\n",
    "    {'weighting': 'rowwise', 'n_neighbors': n_neighbors}, training, data_description\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iknn_scores = iknn_model_scoring(iknn_params, testset, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rating prediction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rmse(iknn_scores, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top-n recommendations quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_seen_items(iknn_scores, testset, data_description)\n",
    "iknn_recs = topn_recommendations(iknn_scores, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluate(iknn_recs, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = ... # name the weighting mode\n",
    "recommended_items = pd.Series(iknn_recs.ravel()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = item_ratings.plot.scatter(\n",
    "    'size', 'mean', logx=True, alpha=0.3, figsize=(8, 6),\n",
    "    title=f'Rating distribution of recommended items, {mode=}'\n",
    ")\n",
    "item_ratings.loc[recommended_items.index].plot.scatter(\n",
    "    'size', 'mean', ax=ax, s=recommended_items*0.05, c='red'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = item_ratings.plot.scatter(\n",
    "    'mean', 'std', s=0.05*item_ratings['size'],\n",
    "    alpha=0.3, figsize=(8, 6),\n",
    "    title=f'Rating deviation of recommended items, {mode=}'\n",
    ");\n",
    "item_ratings.loc[recommended_items.index].plot.scatter(\n",
    "    'mean', 'std', ax=ax, c='red', s=recommended_items*0.05\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>  \n",
    "\n",
    "* Explain why neighborhood sampling changed the picture that way?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymmetric iKNN with column-wise weighting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for column-wise weighting:\n",
    "$$\n",
    "R=A D_S^{-1}S^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asy_iknn_model_scoring(params, testset, testset_description):\n",
    "    item_similarity, weighting = params\n",
    "    user_item_mtx = generate_interactions_matrix(\n",
    "        testset, testset_description, rebase_users=True\n",
    "    )\n",
    "    # implement column-wise weighting, R = A (S D)^T\n",
    "    ... # your code to generate scores\n",
    "\n",
    "    raise ValueError('Unrecognized weighting type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iknn_params_cw = build_sampled_iknn_model(\n",
    "    {'weighting': 'rowwise', 'n_neighbors': n_neighbors}, training, data_description\n",
    ")\n",
    "iknn_scores_cw = asy_iknn_model_scoring(iknn_params_cw, testset, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_seen_items(iknn_scores_cw, testset, data_description)\n",
    "iknn_recs_cw = topn_recommendations(iknn_scores_cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluate(iknn_recs_cw, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-based KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, there's no reason for implementing row-wise weighting scheme in user-based KNN.  \n",
    "So the options are\n",
    "\n",
    "- for element-wise weighting:\n",
    "$$\n",
    "R=K A \\oslash\\left(K B\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "- for unweighted case:\n",
    "$$\n",
    "R=KA\n",
    "$$\n",
    "\n",
    "where $K$ is a user-similarity matrix. \n",
    "\n",
    "Note that the implementation of similarity calculation now has to take into account test users which may be unknown at the build stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_uknn_model(config, data, data_description):\n",
    "    user_item_mtx = generate_interactions_matrix(data, data_description)\n",
    "    # compute similarity matrix and normalization coefficients\n",
    "    user_similarity = ...\n",
    "    weighted = config['weighted']\n",
    "    return user_item_mtx, user_similarity, weighted\n",
    "\n",
    "def uknn_model_scoring(params, testset, testset_description):\n",
    "    user_item_mtx, user_similarity, weighted = params\n",
    "    test_users = testset_description['test_users']\n",
    "\n",
    "    if not weighted:\n",
    "        return ...\n",
    "\n",
    "    normalizer = ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_params_uw = build_uknn_model(\n",
    "    {'weighted': False}, training, data_description\n",
    ")\n",
    "uknn_params_ew = build_uknn_model(\n",
    "    {'weighted': True}, training, data_description\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_scores_uw = uknn_model_scoring(uknn_params_uw, None, data_description)\n",
    "uknn_scores_ew = uknn_model_scoring(uknn_params_ew, None, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top-n recommendations quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_seen_items(uknn_scores_uw, testset, data_description)\n",
    "downvote_seen_items(uknn_scores_ew, testset, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_recs_uw = topn_recommendations(uknn_scores_uw)\n",
    "uknn_recs_ew = topn_recommendations(uknn_scores_ew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['unweighted', 'elementwise']\n",
    "uknn_recs = dict(zip(modes, [uknn_recs_uw, uknn_recs_ew]))\n",
    "\n",
    "\n",
    "uknn_metrics = {}\n",
    "for mode, recs in uknn_recs.items():\n",
    "    uknn_metrics[mode] = metrics = model_evaluate(recs, holdout, data_description)\n",
    "    print(\n",
    "        f'Weighting mode: {mode}\\n'\\\n",
    "        'HR={:.3}, MRR={:.3}, COV={:.3}\\n'.format(*metrics)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_scores = dict(zip(modes, [uknn_scores_uw, uknn_scores_ew]))\n",
    "uknn_rmse = {}\n",
    "for mode, scores in uknn_scores.items():\n",
    "    uknn_rmse[mode] = rmse = calculate_rmse(scores, holdout, data_description)\n",
    "    print(f'Weighting mode: {mode}\\n{rmse=:.3f}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>\n",
    "\n",
    "- Try to explain, why user-based KNN with element-wise weighting provides slightly better RMSE scores than its item-based counterpart?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk run helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "modes = ['unweighted', 'elementwise', 'rowwise']\n",
    "iknn_recs = dict(zip(modes, [iknn_recs_uw, iknn_recs_ew, iknn_recs_rw]))\n",
    "iknn_metrics = {}\n",
    "for mode, recs in iknn_recs.items():\n",
    "    iknn_metrics[mode] = metrics = model_evaluate(recs, holdout, data_description)\n",
    "    print(\n",
    "        f'Weighting mode: {mode}\\n'\\\n",
    "        'HR={:.3}, MRR={:.3}, COV={:.3}\\n'.format(*metrics)\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "iknn_scores = dict(zip(modes, [iknn_scores_uw, iknn_scores_ew, iknn_scores_rw]))\n",
    "iknn_rmse = {}\n",
    "for mode, scores in iknn_scores.items():\n",
    "    iknn_rmse[mode] = rmse = calculate_rmse(scores, holdout, data_description)\n",
    "    print(f'Weighting mode: {mode}\\n{rmse=:.3f}\\n')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rstest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64cd544b7330e8e73b8689d110cc075e8c836a404445c2b82c04f3ea96ea86ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
